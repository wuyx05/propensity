# Marketing Propensity Modeling & Revenue Optimization  

## Overview  
This project predicts client purchase propensity and revenue potential to optimize marketing outreach. It combines classification (purchase likelihood) and regression (revenue prediction) models, followed by a greedy algorithm to prioritize high-value targets.

---

## Data Processing  

### 1. Data Cleaning  
1615 clients, 29 features, 3 binary sales label, 3 numerical regression labels.
- ​**Deduplication**: No duplicates.  
- ​**NA data**: Fill NA with 0.   
- ​**Merging**: Consolidated all dataframes into a single dataset by joining on client ID.  

### 2. Train-Test Split  
- ​**Test Set**: Clients without labels (i.e., unknown purchase/revenue outcomes) were allocated to the test set.     
- ​**Training-Validation Split**:  
  - The remaining clients were split into ​80% training and ​20% validation sets    
  
  
### 3. Feature Engineering  
- ​**Account Balance Columns**:  
Features like account balances exhibited a long right tail (few clients with extremely high values). To normalize these distributions for modeling, negative balances were set to ​0 (enabling log transformation), and a ​log transformation was later applied to reduce skewness.
  <!-- - Replaced negative values with `0` to enable log transformation.  
  - Applied log transformation to address right-tailed skewness.   -->
- ​**Count Columns**: Columns like transaction counts were standardized using ​Z-score scaling (mean = 0, variance = 1) to ensure equal weighting in models.
<!-- Standardized via z-score scaling.   -->
- ​**Categorical Features**: One-hot encoded the `Sex` column.  

---

## Modeling  

### 1. Propensity Models (Classification)  
*Objective*: Predict the likelihood of a client purchasing a product (Credit Card, Mutual Fund, Consumer Loan).   
*Focus on Precision for purchase group*: To minimize wasted marketing resources, models prioritized ​precision (i.e., ensuring clients flagged as "likely to buy" actually buy).   
*Data balancing*: 25%, 18% and 30% of purchase in Credit Card, Mutual Fund, Consumer Loan respectively. Need to take this into consideration during modeling.

#### ***Credit Card***:  
- ​**Models Tested**:  
  - `LightGBM` A gradient-boosted tree optimized via ​5-fold cross-validation with grid search and weight balancing. 
    - Model a. Using precision as metric
    - Model b. Using AUC as metric   
Initial focus on precision (Model a) led to high precision for class 1 and high AUC, indicating good model performance. However, the number of cases identified are very small. Only 7/194 Credit Card buyers are predicted to be target, and lowering decision threshold did not increase the number of identified target much. This has also resulted in ​low recall. Therefore, Model b that uses AUC as the metric is built.  
  - `Logistic Regression` A simpler model using ​AUC as the metric provided balanced precision and recall.    
- ​**Key Results on Validation Set**:  
  | Model          | Precision(Class 1) | Recall(Class 1) | AUC  |  
  |----------------|-----------|--------|------|  
  | LightGBM (precision focused)       | 0.57      | 0.09   | 0.73 |  
  | LightGBM        | 0.33      | 0.38   | 0.63 |  
  | Logistic Regression | 0.31    | 0.45   | 0.56 |  


- ​**Final Choice**: Logistic regression coefficients provide clear insights into feature impacts, and the model’s performance matched LightGBM on validation data, avoiding extreme precision-recall trade-offs.  

**Generalized**: Same approach applied to ***Mutual Fund (`MF`)*** and ***Consumer Loan (`CL`)***.  

### 2. Revenue Models (Regression)  
Objective: Predict revenue generated by clients who purchase a product. Fit models on clients who purchased this product.   
Target Transformation: Revenue was log-transformed to mitigate right skewness, improving regression performance.

#### ***Credit Card***:  
- ​**Models Tested**:  
  - `LightGBM Regressor` Tuned via grid search. This algorithm is too complicated for such a small data set, giving rise to overfit issue and higher error. It also produced tightly clustered predictions on validation data, limiting differentiation between clients(there are only 3 predicted values).  
  - `Linear Regression` Despite simplicity, predictions were more spread out, enabling effective client ranking.  
- ​**Key Results**:  
  | Model          | Validation MAE(log scale) | 
  |----------------|----------------| 
  | LightGBM       | 1.47           | 
  | Linear Regression | 0.68        |
- ​**Final Choice**: Linear regression for interpretability and stable predictions. Also spread predictions allowed clearer prioritization of high-revenue clients.  

**Generalized**: Applied to ***Mutual Fund (`MF`)*** and ***Consumer Loan (`CL`)*** revenue predictions.  

---

## Recommendation Algorithm  

### Expected Revenue Calculation  
For each client-product pair, expected revenue was computed as   
$$
\text{Expected Revenue} = \text{P(Propensity)} \times \text{Predicted Revenue}
$$  
Propensity Thresholding: Pairs with propensity < 0.5 were excluded to avoid targeting unlikely buyers.   
### Greedy Ranking Strategy:   
​Batch Prioritization: Clients were ranked by descending expected revenue. Client-product pair with highest expected revenue are then selected as target.    
​Unique Product per Client: To prevent over-targeting, once a client was selected for one product, they were excluded from subsequent recommendations.   
​Scalability: The greedy algorithm efficiently handles large datasets, aligning with batch-marketing constraints.   

### Final Result:    

Out of top 29 (15% of validation set) client-product pair selected, 10 are actual purchases.   
The total predicted revenue is 128.2 whereas the actual amount is 63.1.

---

## Discussion and future improvement:
**Model Enhancements**    
This approach relies heavily on the performance of underlying propensity and revenue prediction models. Instead of using same features, models can be calibrated using product specific features and tuning.   
​**Dynamic Thresholding**:   
Replace fixed 0.5 propensity threshold with adaptive cutoffs based on business constraints (e.g., campaign budget, target audience size).   
**Alternative Recommendation Algorithm**:  
Collaborative Filtering: Hybridize propensity models with client-product affinity scores.  